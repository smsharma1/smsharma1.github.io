<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Model counting on Academic</title>
    <link>/tags/model-counting/</link>
    <description>Recent content in Model counting on Academic</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Tue, 12 Mar 2019 23:22:03 +0530</lastBuildDate>
    
	<atom:link href="/tags/model-counting/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Knowledge Compilation meets Uniform Sampling</title>
      <link>/post/kus/</link>
      <pubDate>Tue, 12 Mar 2019 23:22:03 +0530</pubDate>
      
      <guid>/post/kus/</guid>
      <description>This blogpost is based on our (Myself, Rahul, Subhajit and Kuldeep) paper that got published in the procedings of International Conference on Logic for Programming, Artificial Intelligence and Reasoning (LPAR), 2018. The code is available here. The primary contribution of this work is marrying knowledge compilation with uniform sampling to design a new uniform sampler KUS. The main result is that KUS is able to solve more number of benchmarks than existing state-of-the art uniform and almost-uniform samplers beating them by orders of magnitude in terms of runtime: Uniform Sampling</description>
    </item>
    
  </channel>
</rss>